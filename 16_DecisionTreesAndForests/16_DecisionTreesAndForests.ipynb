{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9acf77",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "De **supervised learning** techniek Decision Trees voor **classificatie** is iets dat je zelf al goed kent.\n",
    "Je gebruikt ze namelijk zelf onbewust wanneer je een voorwerp moet identificeren.\n",
    "Waar let je bijvoorbeeld op om het onderstaande stuk fruit te identificeren?\n",
    "\n",
    "![apple](images\\apple.png)\n",
    "\n",
    "Hier zou je bijvoorbeeld op de volgende karakteristieken of features gelet kunnen hebben:\n",
    "* Hoe rood is het stuk fruit?\n",
    "* Hoe rond is het stuk fruit\n",
    "* Hoeveel weegt het stuk fruit?\n",
    "\n",
    "Mentaal bouw je dus onbewust een boom op en overloop je een reeks opties om te bepalen of het object waar je naar kijkt een appel is of niet.\n",
    "\n",
    "Dit is net hetgene dat er ook gebruikt bij het opbouwen van een decision tree.\n",
    "Een voorbeeld van de werking van deze classifier is als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e18fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# graphical\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fbd5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1778de079a0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maakt de dataset\n",
    "X, y = datasets.make_classification(n_samples=20, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=2, class_sep=0.3, random_state=123)\n",
    "\n",
    "sns.scatterplot(x=X[:,0], y=X[:, 1], hue=y)\n",
    "plt.plot([0.45, 0.45], [-1.5, 1.2], color=\"black\")\n",
    "plt.plot([-1.2, 0.45], [-0.5, -0.5], color=\"black\")\n",
    "plt.plot([-1.2, 0.45], [1.0, 1.0], color=\"black\")\n",
    "plt.plot([-1.2, 0.45], [0.1, 0.1], color=\"black\")\n",
    "plt.plot([-0.55, -0.55], [0.1, 1.0], color=\"black\")\n",
    "plt.plot([0, 0], [0.1, -0.5], color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94da7f",
   "metadata": {},
   "source": [
    "Voor bovenstaande voorbeeld kan bijvoorbeeld deze boom opgebouwd worden die de classificatie doet:\n",
    "\n",
    "![boom](images\\boom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf61b18",
   "metadata": {},
   "source": [
    "## Bepalen scheidingslijnen\n",
    "\n",
    "Hierboven hebben we zelf de lijnen getrokken om het gebied in twee te verdelen.\n",
    "Nu rest er nog de vraag, hoe kiezen we de beste lijnen om deze verdeling te doen.\n",
    "Intuitief denk je dan aan de lijn die het grootste aantal observaties van dezelfde klasse afsplitst. \n",
    "Of de lijn die het minste fouten maakt.\n",
    "\n",
    "Deze intuitieve benadering komt sterk overeen met het berekenen van de entropie en deze proberen zo laag mogelijk te krijgen.\n",
    "Entropie is een maat voor de wanorde/chaos in een systeem en wordt gebruikt in een aantal wetenschappelijke disciplines zoals chemie en fysica maar ook in computerwetenschappen bij bijvoorbeeld encryptie en compressie. \n",
    "Hoe hoger de entropie in een bepaald systeem, hoe hoger de wanorde/chaos en bijvoorbeeld hoe beter de encryptie.\n",
    "De entropie van een classificatieprobleem kan als volgt bepaald worden:\n",
    "\n",
    "$H = \\sum\\limits_{i=1}^{N} p_i \\log_2(\\frac{1}{p_i}) = -\\sum\\limits_{i=1}^{N} p_i \\log_2(p_i)$\n",
    "\n",
    "waar $p_i$ het percentage observaties van klasse $i$ is in het gebied.\n",
    "\n",
    "De entropie van de beginsituatie in bovenstaand voorbeeld en na de eerste split kan berekend worden als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255eed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1778de93850>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.1,1,0.01)\n",
    "y = x * np.log2(x) + (1-x) * np.log2(1-x)\n",
    "plt.plot(x,-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16f7afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47368421052631576 0.5263157894736842 0.9980008838722996\n",
      "1e-07 1.0 2.3253496664211536e-06\n",
      "0.6923076923076923 0.3076923076923077 0.8904916402194913\n",
      "Information Gain =  0.3887163957169635\n"
     ]
    }
   ],
   "source": [
    "pBeginKlasse0 = 9/19 # blauwe punten\n",
    "pBeginKlasse1 = 10/19 # orange punten\n",
    "\n",
    "entropieBegin = - (pBeginKlasse0 * np.log2(pBeginKlasse0) + pBeginKlasse1 * np.log2(pBeginKlasse1))\n",
    "print(pBeginKlasse0, pBeginKlasse1, entropieBegin)\n",
    "# Dit geeft een zeer hoge entropie voor in het begin.\n",
    "\n",
    "pLinksKlasse0 = 9/13\n",
    "pLinksKlasse1 = 4/13\n",
    "pRechtsKlasse0 = 0.0000001 # Dit moet 0 zijn maar zou eindigen in min oneindig. (vandaar een minieme waarde)\n",
    "pRechtsKlasse1 = 6/6\n",
    "\n",
    "entropieRechts = - (pRechtsKlasse0 * np.log2(pRechtsKlasse0) + pRechtsKlasse1 * np.log2(pRechtsKlasse1))\n",
    "print(pRechtsKlasse0, pRechtsKlasse1, entropieRechts)\n",
    "entropieLinks = - (pLinksKlasse0 * np.log2(pLinksKlasse0) + pLinksKlasse1 * np.log2(pLinksKlasse1))\n",
    "print(pLinksKlasse0, pLinksKlasse1, entropieLinks)\n",
    "informationGain = entropieBegin - 6/19 * entropieRechts - 13/19 * entropieLinks\n",
    "print(\"Information Gain = \", informationGain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c867e0",
   "metadata": {},
   "source": [
    "Na het berekenen van de gewenste information gain voor alle splits die je kan doen, moet je de beste kiezen. \n",
    "Hiervoor kiezen we dan degene die de grootste hoeveelheid informatie toevoegt.\n",
    "\n",
    "Er is echter een groot nadeel aan het gebruik van de entropie.\n",
    "Het veelvuldig berekenen van de logaritmes voor alle mogelijke verdeling is zeer rekenintensief.\n",
    "Daarom is het beter om gebruik te maken van een alternatieve methode om de scheidingslijn te bepalen.\n",
    "Deze methode noemt de Gini impurity methode en is default gekozen bij de Decision Tree algoritmes van sklearn.\n",
    "De Gini impurity focust meer op de zuiverheid van de verdeling en minder op de entropie en kan berekend worden als volgt:\n",
    "\n",
    "$G = 1 - \\sum\\limits_{i=1}^{N}p_i^2$\n",
    "\n",
    "Om nu de beste verdelingslijn te zoeken neem je de lijn die leidt tot de kleinste Gini impurity.\n",
    "Let er wel op dat je het gewogen gemiddelde neemt van de twee delen om de Gini impurity waarden te vergelijken.\n",
    "De berekening van de Gini Impurity voor de eerste verdeling van bovenstaande voorbeeld gaat als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e318dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29149797570849884\n"
     ]
    }
   ],
   "source": [
    "GLinks = 1 - pLinksKlasse0**2 - pLinksKlasse1**2\n",
    "GRechts = 1 - pRechtsKlasse0**2 - pRechtsKlasse1**2\n",
    "G = 13/19*GLinks + 6/19*GRechts\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1cdc4f",
   "metadata": {},
   "source": [
    "Net zoals bij de voorgaande machine learning technieken hebben ook Decision Trees hun voor en nadelen.\n",
    "De nadelen zijn:\n",
    "* Grote neiging tot overfitting\n",
    "* Gevoelig aan ruis\n",
    "* Boom kan zeer groot worden\n",
    "\n",
    "Het vordeel van een decision tree is dat het een zeer snelle en eenvoudige techniek is die snel een resultaat kan leveren maar het belangrijkste voordeel waardoor het nog steeds vaak gebruikt wordt is dat je op het resulterende model kan redeneren.\n",
    "Dat wil zeggen dat je kan kijken welke features de grootste impact hebben op het resultaat, waar de verdelingslijnen geplaatst worden en waarom. \n",
    "Deze redenering en analyse kan dan gebruikt worden om je processen eventueel te verbeteren. \n",
    "\n",
    "Hoewel Decision Trees gevoelig zijn aan overfitting zijn er een groot aantal manieren om regularisatie toe te voegen aan het algoritme.\n",
    "De belangrijkste hyperparameters om dit te doen zijn:\n",
    "* max_depth: Beperk de maximale diepte van de boom\n",
    "* min_samples_split: Laat geen verdelingen toe van gebieden met minder observaties dan deze waarde. De klasse van het gebied komt dan overeen met de meerderheid van de observaties\n",
    "* min_samples_leaf: Minimum aantal observaties als blad van de boom\n",
    "\n",
    "Train nu een [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) op de borstkanker dataset van sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cde9216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc train data 1.0\n",
      "Acc test data 0.8557504873294347\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.07130125 0.         0.02275349 0.04991087 0.\n",
      " 0.         0.         0.         0.78752228 0.06851211 0.        ]\n",
      "Most important feature = worst concave points with index:  27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = datasets.load_breast_cancer(as_frame=True)\n",
    "display(cancer[\"frame\"].head())\n",
    "\n",
    "# train test split\n",
    "X = cancer[\"frame\"].drop(\"target\", axis=1)\n",
    "y = cancer[\"frame\"].target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)\n",
    "\n",
    "# make decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# train en predict\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# toon score\n",
    "print(\"Acc train data\", clf.score(X_train, y_train))\n",
    "print(\"Acc test data\", clf.score(X_test, y_test))\n",
    "\n",
    "# toon belangrijke features \n",
    "print(clf.feature_importances_)\n",
    "for idx, val in enumerate(clf.feature_importances_):\n",
    "    if val == np.max(clf.feature_importances_):\n",
    "        print(\"Most important feature =\", cancer.data.columns[idx], \"with index: \", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f50aaa",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "Een andere manier om overfitting van decision trees tegen te gaan en het resultaat accurater te maken is door gebruik te maken van Random Forests.\n",
    "Deze techniek gaat meerdere decision trees trainen en door gebruik van majority voting alle trees laten stemmen over het uiteindelijke resultaat.\n",
    "Buiten het vermijden van problemen door overfitting kan deze techniek ook veel accurater zijn.\n",
    "Algemeen gezien kan men zelfs er van uitgaan dat hoe meer trees er gebruikt worden hoe accurater het forest wordt.\n",
    "\n",
    "Omdat we meerdere bomen gebruiken willen we ook meer variatie in de modellen die deze bomen leren.\n",
    "Daarom wordt elke boom maar op een willekeurig deel van de data getrained (vandaar de term random).\n",
    "\n",
    "Buiten de hyperparameters die voor de decision trees gebruikt kunnen worden zijn er nog een aantal extra zaken die de performantie van het gecombineerde forest sterk kan verbeteren, namelijk:\n",
    "* n_estimators: Het aantal bomen dat gebruikt wordt (Hoe meer bomen hoe accurater maar ook hoe meer rekenkracht)\n",
    "* max_features: Aantal features per boom (int, float, sqrt / auto, log2, default). Hoe meer features, hoe meer kans op overfitting\n",
    "* Bootstrap aggregating of bagging: Dit houdt in dat maar een deel van de observaties gebruikt worden om elke boom te trainen. Zo kan er meer variatie geintroduceerd worden.\n",
    "* oob_score: Out-of-Bag score: Het trainen van een decision tree gebruikt niet alle trainingsdata dus kan je de niet-gebruikte data gebruiken als validatieset voor die boom. Meer informatie vind je [hier](https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710)\n",
    "\n",
    "Waarom zou je een Random Forest Classifier verkiezen boven een classifier gebaseerd op Logistic Regression of SVM?\n",
    "Random forest classifiers hebben de volgende voordelen:\n",
    "* Ze zijn zeer goed in te stellen\n",
    "* Ze vragen niet veel rekenkracht\n",
    "* Hun accuraatheid is gelijk aan dat van SVM of zelfs beter\n",
    "* Het voordeel van decision trees dat er kan geredeneerd worden op welke features belangrijk zijn blijft behouden. \n",
    "\n",
    "Net zoals voor de vorige classifiers kan ook deze techniek gebruikt worden voor regressie.\n",
    "In dit geval moet er gebruik gemaakt worden van het gemiddelde in plaats van majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daa7cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc train data 0.9642857142857143\n",
      "Acc test data 0.8226120857699805\n",
      "[0.         0.         0.         0.52492047 0.         0.\n",
      " 0.         0.05533597 0.         0.         0.         0.03154901\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11492855\n",
      " 0.         0.         0.16786416 0.         0.10540184 0.        ]\n",
      "Most important feature = mean area with index:  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=1)\n",
    "\n",
    "# train en predict\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# score\n",
    "print(\"Acc train data\", clf.score(X_train, y_train))\n",
    "print(\"Acc test data\", clf.score(X_test, y_test))\n",
    "\n",
    "# toon belangrijke features \n",
    "print(clf.feature_importances_)\n",
    "for idx, val in enumerate(clf.feature_importances_):\n",
    "    if val == np.max(clf.feature_importances_):\n",
    "        print(\"Most important feature =\", cancer.data.columns[idx], \"with index: \", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc3966",
   "metadata": {},
   "source": [
    "Train nu meerdere random-forest classifiers waar je het aantal estimators laat toenemen (bvb tot 100).\n",
    "Toon een plot met de trainings en test error in functie van het aantal estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793c98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
